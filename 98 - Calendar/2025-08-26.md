
Compare a specific scenario to the other baseline (just the centralized as we did the other one implicitly with labeled_fraction = 1) on the metric score radar plot
Try with 1 client for same amount of time (ofc overfitting but still)
and try with 10 clients but more time 
--> identifies issue might be fedavg
> Note: Ask them what to do about this, do I just keep this even though I know its the main issue?

I think the issue is that the more lamda_u we allow, the more the models diverge & therefore fedavg hurts.

The higher the alpha (more iid), the more we see that 0.5/0.2 labeled fraction outperforms, still , the lambda_us often harm performance. We dont know if this is due to stm or not.
Then try with different values for stm (on / off, sorted / diff sizes) for 1 scenario

DO NOT FORGET TO ALTER DIR IN SAVE_RESULTS!!!! AND HYPERPARAMCONFIG

Should run tests with stm off to compare

~~Should run same tests but with 1 client or 2 clients?~~