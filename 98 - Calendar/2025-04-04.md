Discussed:
Mix of labelled & unlabelled data ==> combined supervised & unsupervised (maybe just use their labels rather than pseudo labels)
Combine their losses with lambda
Non-iid of data: randomizing might affect inherent bias
Look up data inbalance, how to handle this best and such.
semi-sl
pipeline --> models to semi-supervised
and a full supervised hyperparam lambda to 0





Email simon:

I had a couple of interesting reads specifically about Semi-SL:
- Do not trust what you trust:  [https://arxiv.org/pdf/2403.15567](https://arxiv.org/pdf/2403.15567 "https://arxiv.org/pdf/2403.15567")

-> concerned with testing SOTA methods (mostly FlexMatch) on their calibration
-> proposal of method to recalibrate

- RoPAWS: [https://arxiv.org/pdf/2302.14483](https://arxiv.org/pdf/2302.14483 "https://arxiv.org/pdf/2302.14483")
-> extension of PAWS: [https://arxiv.org/pdf/2104.13963](https://arxiv.org/pdf/2104.13963 "https://arxiv.org/pdf/2104.13963") (seems to be what we could consider as SOTA)

-> recalibration of predictions 
  
Otherwise, it might be worth it to have a look at the current SOTA according to:
https://paperswithcode.com/task/semi-supervised-image-classification