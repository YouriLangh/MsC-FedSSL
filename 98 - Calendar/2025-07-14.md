Look into pseudo label generation & distribution

add retention of pseudolabels for X rounds  = 
Fix loading data & look into how pseudolabels can be saved for X rounds. Just adjdust trainloader? or keep a dictionary ==> simpler
- <span style="color:rgb(255, 0, 0)">Use dataset metadata such that models load only their own data</span>
>add precision?

~~Situate our paper in the field EXACTLY. dont need to use all papers. Just make sure to have some SSL, Fed, FedSSL and then the 3 diff scenarios (labels at client ....) (and mention we only focus on XYZ and not securtiy or communication efficiency)~~

Read FedProx & FreeMatch  & FlexMatch

Make SSL diagram

SSL= FixMatch, FlexMatch, FreeMatch
Federated Learning= FedAvg,
FedSSL = 
- (Fix+FedAvg)= 
	- [Federated Semi-Supervised Learning with Inter-Client Consistency & Disjoint Learning](https://doi.org/10.48550/arXiv.2006.12097)
	- [Federated semi-supervised learning with contrastive representations against noisy labels](https://doi.org/10.1016/j.asoc.2025.113421)
	- [ (DDRFed) Dynamic Class-Balanced Threshold Federated Semi-Supervised Learning](https://doi.org/10.1016/j.future.2025.107820)
- Adaptive thresholds (idea, not always exactly like us): 
	- [DDRFed](https://doi.org/10.1016/j.future.2025.107820), [SemiFed](https://doi.org/10.48550/arXiv.2108.09412), [FlexMatch](https://doi.org/10.48550/arXiv.2110.08263), [FreeMatch](https://doi.org/10.48550/arXiv.2205.07246) and [CBAFed](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Class_Balanced_Adaptive_Pseudo_Labeling_for_Federated_Semi-Supervised_Learning_CVPR_2023_paper.html)
- Idea for retention of pseudo-labels for X rounds: [CBDPL](http://doi.org/10.1109/ACCESS.2025.3576875) 
<span style="color:rgb(255, 0, 0)">predictions scatter plot with color = actual label ==> How do the positions work in this? ==> HARD</span>

perhaps switch to resnet9 for the moment. ==> ZZZZ, talk to simon perhaps abt this?