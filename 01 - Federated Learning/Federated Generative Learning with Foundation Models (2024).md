#FL #Image 

A text embedding is a numerical representation of text in a multi-dimensional space, capturing its meaning and relationships

This paper is based on creating representation of the private datasets of clients and sending these embeddings to the server. The server can then generate a dataset to train, possibly ending up as a one-shot algorithm.

As their baselines they use Federated learning on one side and Centralized on the other.

To Test for Membership Inference Attacks (MIA) have to use LiRA

![[Federated Generative Learning with Foundation Models.pdf]]